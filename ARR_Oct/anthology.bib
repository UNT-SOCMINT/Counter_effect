% Please download the latest anthology.bib from
%
% http://aclweb.org/anthology/anthology.bib.gz
@inproceedings{qian-etal-2019-benchmark,
	title = "A Benchmark Dataset for Learning to Intervene in Online Hate Speech",
	author = "Qian, Jing  and
	Bethke, Anna  and
	Liu, Yinyin  and
	Belding, Elizabeth  and
	Wang, William Yang",
	booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
	month = nov,
	year = "2019",
	address = "Hong Kong, China",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/D19-1482",
	doi = "10.18653/v1/D19-1482",
	pages = "4755--4764",
}

@inproceedings{rosenthal-etal-2017-semeval,
	title = "{S}em{E}val-2017 Task 4: Sentiment Analysis in {T}witter",
	author = "Rosenthal, Sara  and
	Farra, Noura  and
	Nakov, Preslav",
	booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)",
	month = aug,
	year = "2017",
	address = "Vancouver, Canada",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/S17-2088",
	doi = "10.18653/v1/S17-2088",
	pages = "502--518",
	abstract = "This paper describes the fifth year of the Sentiment Analysis in Twitter task. SemEval-2017 Task 4 continues with a rerun of the subtasks of SemEval-2016 Task 4, which include identifying the overall sentiment of the tweet, sentiment towards a topic with classification on a two-point and on a five-point ordinal scale, and quantification of the distribution of sentiment towards a topic across a number of tweets: again on a two-point and on a five-point ordinal scale. Compared to 2016, we made two changes: (i) we introduced a new language, Arabic, for all subtasks, and (ii) we made available information from the profiles of the Twitter users who posted the target tweets. The task continues to be very popular, with a total of 48 teams participating this year.",
}

@inproceedings{ghosh-etal-2020-report,
	title = "A Report on the 2020 Sarcasm Detection Shared Task",
	author = "Ghosh, Debanjan  and
	Vajpayee, Avijit  and
	Muresan, Smaranda",
	booktitle = "Proceedings of the Second Workshop on Figurative Language Processing",
	month = jul,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2020.figlang-1.1",
	doi = "10.18653/v1/2020.figlang-1.1",
	pages = "1--11",
}

@inproceedings{shnarch-etal-2018-will,
	title = "Will it Blend? Blending Weak and Strong Labeled Data in a Neural Network for Argumentation Mining",
	author = "Shnarch, Eyal  and
	Alzate, Carlos  and
	Dankin, Lena  and
	Gleize, Martin  and
	Hou, Yufang  and
	Choshen, Leshem  and
	Aharonov, Ranit  and
	Slonim, Noam",
	booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
	month = jul,
	year = "2018",
	address = "Melbourne, Australia",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/P18-2095",
	doi = "10.18653/v1/P18-2095",
	pages = "599--605",
}


@inproceedings{vidgen-etal-2021-introducing,
	title = "Introducing {CAD}: the Contextual Abuse Dataset",
	author = "Vidgen, Bertie  and
	Nguyen, Dong  and
	Margetts, Helen  and
	Rossini, Patricia  and
	Tromble, Rebekah",
	booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
	month = jun,
	year = "2021",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2021.naacl-main.182",
	doi = "10.18653/v1/2021.naacl-main.182",
	pages = "2289--2303",
	abstract = "Online abuse can inflict harm on users and communities, making online spaces unsafe and toxic. Progress in automatically detecting and classifying abusive content is often held back by the lack of high quality and detailed datasets.We introduce a new dataset of primarily English Reddit entries which addresses several limitations of prior work. It (1) contains six conceptually distinct primary categories as well as secondary categories, (2) has labels annotated in the context of the conversation thread, (3) contains rationales and (4) uses an expert-driven group-adjudication process for high quality annotations. We report several baseline models to benchmark the work of future researchers. The annotated dataset, annotation guidelines, models and code are freely available.",
}

@inproceedings{vidgen-etal-2019-challenges,
	title = "Challenges and frontiers in abusive content detection",
	author = "Vidgen, Bertie  and
	Harris, Alex  and
	Nguyen, Dong  and
	Tromble, Rebekah  and
	Hale, Scott  and
	Margetts, Helen",
	booktitle = "Proceedings of the Third Workshop on Abusive Language Online",
	month = aug,
	year = "2019",
	address = "Florence, Italy",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/W19-3509",
	doi = "10.18653/v1/W19-3509",
	pages = "80--93",
	abstract = "Online abusive content detection is an inherently difficult task. It has received considerable attention from academia, particularly within the computational linguistics community, and performance appears to have improved as the field has matured. However, considerable challenges and unaddressed frontiers remain, spanning technical, social and ethical dimensions. These issues constrain the performance, efficiency and generalizability of abusive content detection systems. In this article we delineate and clarify the main challenges and frontiers in the field, critically evaluate their implications and discuss potential solutions. We also highlight ways in which social scientific insights can advance research. We discuss the lack of support given to researchers working with abusive content and provide guidelines for ethical research.",
}

@inproceedings{wiegand-etal-2019-detection,
	title = "{D}etection of {A}busive {L}anguage: the {P}roblem of {B}iased {D}atasets",
	author = "Wiegand, Michael  and
	Ruppenhofer, Josef  and
	Kleinbauer, Thomas",
	booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
	month = jun,
	year = "2019",
	address = "Minneapolis, Minnesota",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/N19-1060",
	doi = "10.18653/v1/N19-1060",
	pages = "602--608",
	abstract = "We discuss the impact of data bias on abusive language detection. We show that classification scores on popular datasets reported in previous work are much lower under realistic settings in which this bias is reduced. Such biases are most notably observed on datasets that are created by focused sampling instead of random sampling. Datasets with a higher proportion of implicit abuse are more affected than datasets with a lower proportion.",
}

@inproceedings{guest-etal-2021-expert,
	title = "An Expert Annotated Dataset for the Detection of Online Misogyny",
	author = "Guest, Ella  and
	Vidgen, Bertie  and
	Mittos, Alexandros  and
	Sastry, Nishanth  and
	Tyson, Gareth  and
	Margetts, Helen",
	booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
	month = apr,
	year = "2021",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2021.eacl-main.114",
	doi = "10.18653/v1/2021.eacl-main.114",
	pages = "1336--1350",
	abstract = "Online misogyny is a pernicious social problem that risks making online platforms toxic and unwelcoming to women. We present a new hierarchical taxonomy for online misogyny, as well as an expert labelled dataset to enable automatic classification of misogynistic content. The dataset consists of 6567 labels for Reddit posts and comments. As previous research has found untrained crowdsourced annotators struggle with identifying misogyny, we hired and trained annotators and provided them with robust annotation guidelines. We report baseline classification performance on the binary classification task, achieving accuracy of 0.93 and F1 of 0.43. The codebook and datasets are made freely available for future researchers.",
}

@inproceedings{phang2020jiant,
	title = "jiant: A Software Toolkit for Research on General-Purpose Text Understanding Models",
	author = "Pruksachatkun, Yada  and
	Yeres, Phil  and
	Liu, Haokun  and
	Phang, Jason  and
	Htut, Phu Mon  and
	Wang, Alex  and
	Tenney, Ian  and
	Bowman, Samuel R.",
	booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
	month = jul,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2020.acl-demos.15",
	doi = "10.18653/v1/2020.acl-demos.15",
	pages = "109--117",
	abstract = "We introduce jiant, an open source toolkit for conducting multitask and transfer learning experiments on English NLU tasks. jiant enables modular and configuration driven experimentation with state-of-the-art models and a broad set of tasks for probing, transfer learning, and multitask training experiments. jiant implements over 50 NLU tasks, including all GLUE and SuperGLUE benchmark tasks. We demonstrate that jiant reproduces published performance on a variety of tasks and models, e.g., RoBERTa and BERT.",
}

@inproceedings{chakrabarty-etal-2019-ampersand,
	title = "{AMPERSAND}: Argument Mining for {PERS}u{A}sive o{N}line Discussions",
	author = "Chakrabarty, Tuhin  and
	Hidey, Christopher  and
	Muresan, Smaranda  and
	McKeown, Kathy  and
	Hwang, Alyssa",
	booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
	month = nov,
	year = "2019",
	address = "Hong Kong, China",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/D19-1291",
	doi = "10.18653/v1/D19-1291",
	pages = "2933--2943",
	abstract = "Argumentation is a type of discourse where speakers try to persuade their audience about the reasonableness of a claim by presenting supportive arguments. Most work in argument mining has focused on modeling arguments in monologues. We propose a computational model for argument mining in online persuasive discussion forums that brings together the micro-level (argument as product) and macro-level (argument as process) models of argumentation. Fundamentally, this approach relies on identifying relations between components of arguments in a discussion thread. Our approach for relation prediction uses contextual information in terms of fine-tuning a pre-trained language model and leveraging discourse relations based on Rhetorical Structure Theory. We additionally propose a candidate selection method to automatically predict what parts of one{'}s argument will be targeted by other participants in the discussion. Our models obtain significant improvements compared to recent state-of-the-art approaches using pointer networks and a pre-trained language model.",
}

@inproceedings{jo-etal-2020-detecting,
	title = "Detecting Attackable Sentences in Arguments",
	author = "Jo, Yohan  and
	Bang, Seojin  and
	Manzoor, Emaad  and
	Hovy, Eduard  and
	Reed, Chris",
	booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
	month = nov,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2020.emnlp-main.1",
	doi = "10.18653/v1/2020.emnlp-main.1",
	pages = "1--23",
	abstract = "Finding attackable sentences in an argument is the first step toward successful refutation in argumentation. We present a first large-scale analysis of sentence attackability in online arguments. We analyze driving reasons for attacks in argumentation and identify relevant characteristics of sentences. We demonstrate that a sentence{'}s attackability is associated with many of these characteristics regarding the sentence{'}s content, proposition types, and tone, and that an external knowledge source can provide useful information about attackability. Building on these findings, we demonstrate that machine learning models can automatically detect attackable sentences in arguments, significantly better than several baselines and comparably well to laypeople.",
}

@inproceedings{chung-etal-2021-multilingual,
	title = "Multilingual Counter Narrative Type Classification",
	author = "Chung, Yi-Ling  and
	Guerini, Marco  and
	Agerri, Rodrigo",
	booktitle = "Proceedings of the 8th Workshop on Argument Mining",
	month = nov,
	year = "2021",
	address = "Punta Cana, Dominican Republic",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2021.argmining-1.12",
	doi = "10.18653/v1/2021.argmining-1.12",
	pages = "125--132",
	abstract = "The growing interest in employing counter narratives for hatred intervention brings with it a focus on dataset creation and automation strategies. In this scenario, learning to recognize counter narrative types from natural text is expected to be useful for applications such as hate speech countering, where operators from non-governmental organizations are supposed to answer to hate with several and diverse arguments that can be mined from online sources. This paper presents the first multilingual work on counter narrative type classification, evaluating SoTA pre-trained language models in monolingual, multilingual and cross-lingual settings. When considering a fine-grained annotation of counter narrative classes, we report strong baseline classification results for the majority of the counter narrative types, especially if we translate every language to English before cross-lingual prediction. This suggests that knowledge about counter narratives can be successfully transferred across languages.",
}

@inproceedings{waseem-hovy-2016-hateful,
	title = "Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on {T}witter",
	author = "Waseem, Zeerak  and
	Hovy, Dirk",
	booktitle = "Proceedings of the {NAACL} Student Research Workshop",
	month = jun,
	year = "2016",
	address = "San Diego, California",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/N16-2013",
	doi = "10.18653/v1/N16-2013",
	pages = "88--93",
}

@inproceedings{gao-huang-2017-detecting,
	title = "Detecting Online Hate Speech Using Context Aware Models",
	author = "Gao, Lei  and
	Huang, Ruihong",
	booktitle = "Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",
	month = sep,
	year = "2017",
	address = "Varna, Bulgaria",
	publisher = "INCOMA Ltd.",
	url = "https://doi.org/10.26615/978-954-452-049-6_036",
	doi = "10.26615/978-954-452-049-6_036",
	pages = "260--266",
}

@inproceedings{zhang-etal-2018-conversations,
	title = "Conversations Gone Awry: Detecting Early Signs of Conversational Failure",
	author = "Zhang, Justine  and
	Chang, Jonathan  and
	Danescu-Niculescu-Mizil, Cristian  and
	Dixon, Lucas  and
	Hua, Yiqing  and
	Taraborelli, Dario  and
	Thain, Nithum",
	booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = jul,
	year = "2018",
	address = "Melbourne, Australia",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/P18-1125",
	doi = "10.18653/v1/P18-1125",
	pages = "1350--1361",
	abstract = "One of the main challenges online social systems face is the prevalence of antisocial behavior, such as harassment and personal attacks. In this work, we introduce the task of predicting from the very start of a conversation whether it will get out of hand. As opposed to detecting undesirable behavior after the fact, this task aims to enable early, actionable prediction at a time when the conversation might still be salvaged. To this end, we develop a framework for capturing pragmatic devices{---}such as politeness strategies and rhetorical prompts{---}used to start a conversation, and analyze their relation to its future trajectory. Applying this framework in a controlled setting, we demonstrate the feasibility of detecting early warning signs of antisocial behavior in online discussions.",
}

@inproceedings{chung-etal-2019-conan,
	title = "{CONAN} - {CO}unter {NA}rratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech",
	author = "Chung, Yi-Ling  and
	Kuzmenko, Elizaveta  and
	Tekiroglu, Serra Sinem  and
	Guerini, Marco",
	booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
	month = jul,
	year = "2019",
	address = "Florence, Italy",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/P19-1271",
	doi = "10.18653/v1/P19-1271",
	pages = "2819--2829",
}

@inproceedings{garland-etal-2020-countering,
	title = "Countering hate on social media: Large scale classification of hate and counter speech",
	author = "Garland, Joshua  and
	Ghazi-Zahedi, Keyan  and
	Young, Jean-Gabriel  and
	H{\'e}bert-Dufresne, Laurent  and
	Galesic, Mirta",
	booktitle = "Proceedings of the Fourth Workshop on Online Abuse and Harms",
	month = nov,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2020.alw-1.13",
	doi = "10.18653/v1/2020.alw-1.13",
	pages = "102--112",
}

@inproceedings{tekiroglu-etal-2020-generating,
	title = "Generating Counter Narratives against Online Hate Speech: Data and Strategies",
	author = "Tekiro{\u{g}}lu, Serra Sinem  and
	Chung, Yi-Ling  and
	Guerini, Marco",
	booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
	month = jul,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2020.acl-main.110",
	doi = "10.18653/v1/2020.acl-main.110",
	pages = "1177--1190",
	abstract = "Recently research has started focusing on avoiding undesired effects that come with content moderation, such as censorship and overblocking, when dealing with hatred online. The core idea is to directly intervene in the discussion with textual responses that are meant to counter the hate content and prevent it from further spreading. Accordingly, automation strategies, such as natural language generation, are beginning to be investigated. Still, they suffer from the lack of sufficient amount of quality data and tend to produce generic/repetitive responses. Being aware of the aforementioned limitations, we present a study on how to collect responses to hate effectively, employing large scale unsupervised language models such as GPT-2 for the generation of silver data, and the best annotation strategies/neural architectures that can be used for data filtering before expert validation/post-editing.",
}

@inproceedings{fanton-etal-2021-human,
	title = "Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative Dataset to Fight Online Hate Speech",
	author = "Fanton, Margherita  and
	Bonaldi, Helena  and
	Tekiro{\u{g}}lu, Serra Sinem  and
	Guerini, Marco",
	booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
	month = aug,
	year = "2021",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2021.acl-long.250",
	doi = "10.18653/v1/2021.acl-long.250",
	pages = "3226--3240",
}

@inproceedings{yu-etal-2022-hate,
	title = "Hate Speech and Counter Speech Detection: Conversational Context Does Matter",
	author = "Yu, Xinchen  and
	Blanco, Eduardo  and
	Hong, Lingzi",
	booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
	month = jul,
	year = "2022",
	address = "Seattle, United States",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2022.naacl-main.433",
	doi = "10.18653/v1/2022.naacl-main.433",
	pages = "5918--5930",
	abstract = "Hate speech is plaguing the cyberspace along with user-generated content. Adding counter speech has become an effective way to combat hate speech online. Existing datasets and models target either (a) hate speech or (b) hate and counter speech but disregard the context. This paper investigates the role of context in the annotation and detection of online hate and counter speech, where context is defined as the preceding comment in a conversation thread. We created a context-aware dataset for a 3-way classification task on Reddit comments: hate speech, counter speech, or neutral. Our analyses indicate that context is critical to identify hate and counter speech: human judgments change for most comments depending on whether we show annotators the context. A linguistic analysis draws insights into the language people use to express hate and counter speech. Experimental results show that neural networks obtain significantly better results if context is taken into account. We also present qualitative error analyses shedding light into (a) when and why context is beneficial and (b) the remaining errors made by our best model when context is taken into account.",
}

@inproceedings{zhu-bhat-2021-generate,
	title = "Generate, Prune, Select: A Pipeline for Counterspeech Generation against Online Hate Speech",
	author = "Zhu, Wanzheng  and
	Bhat, Suma",
	booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
	month = aug,
	year = "2021",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2021.findings-acl.12",
	doi = "10.18653/v1/2021.findings-acl.12",
	pages = "134--149",
}

@inproceedings{schmidt-wiegand-2017-survey,
	title = "A Survey on Hate Speech Detection using Natural Language Processing",
	author = "Schmidt, Anna  and
	Wiegand, Michael",
	booktitle = "Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media",
	month = apr,
	year = "2017",
	address = "Valencia, Spain",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/W17-1101",
	doi = "10.18653/v1/W17-1101",
	pages = "1--10",
	abstract = "This paper presents a survey on hate speech detection. Given the steadily growing body of social media content, the amount of online hate speech is also increasing. Due to the massive scale of the web, methods that automatically detect hate speech are required. Our survey describes key areas that have been explored to automatically recognize these types of utterances using natural language processing. We also discuss limits of those approaches.",
}

@inproceedings{fancellu-etal-2016-neural,
	title = "Neural Networks For Negation Scope Detection",
	author = "Fancellu, Federico  and
	Lopez, Adam  and
	Webber, Bonnie",
	booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
	month = aug,
	year = "2016",
	address = "Berlin, Germany",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/P16-1047",
	doi = "10.18653/v1/P16-1047",
	pages = "495--504",
}

@inproceedings{sadeque-etal-2019-incivility,
	title = "Incivility Detection in Online Comments",
	author = "Sadeque, Farig  and
	Rains, Stephen  and
	Shmargad, Yotam  and
	Kenski, Kate  and
	Coe, Kevin  and
	Bethard, Steven",
	booktitle = "Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019)",
	month = jun,
	year = "2019",
	address = "Minneapolis, Minnesota",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/S19-1031",
	doi = "10.18653/v1/S19-1031",
	pages = "283--291",
	abstract = "Incivility in public discourse has been a major concern in recent times as it can affect the quality and tenacity of the discourse negatively. In this paper, we present neural models that can learn to detect name-calling and vulgarity from a newspaper comment section. We show that in contrast to prior work on detecting toxic language, fine-grained incivilities like namecalling cannot be accurately detected by simple models like logistic regression. We apply the models trained on the newspaper comments data to detect uncivil comments in a Russian troll dataset, and find that despite the change of domain, the model makes accurate predictions.",
}

@inproceedings{ashida-komachi-2022-towards,
	title = "Towards Automatic Generation of Messages Countering Online Hate Speech and Microaggressions",
	author = "Ashida, Mana  and
	Komachi, Mamoru",
	booktitle = "Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH)",
	month = jul,
	year = "2022",
	address = "Seattle, Washington (Hybrid)",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2022.woah-1.2",
	doi = "10.18653/v1/2022.woah-1.2",
	pages = "11--23",
	abstract = "With the widespread use of social media, online hate is increasing, and microaggressions are receiving attention. We explore the potential for using pretrained language models to automatically generate messages that combat the associated offensive texts. Specifically, we focus on using prompting to steer model generation as it requires less data and computation than fine-tuning. We also propose a human evaluation perspective; offensiveness, stance, and informativeness. After obtaining 306 counterspeech and 42 microintervention messages generated by GPT-{2, 3, Neo}, we conducted a human evaluation using Amazon Mechanical Turk. The results indicate the potential of using prompting in the proposed generation task. All the generated texts along with the annotation are published to encourage future research on countering hate and microaggressions online.",
}

@inproceedings{niculae-etal-2015-linguistic,
	title = "Linguistic Harbingers of Betrayal: A Case Study on an Online Strategy Game",
	author = "Niculae, Vlad  and
	Kumar, Srijan  and
	Boyd-Graber, Jordan  and
	Danescu-Niculescu-Mizil, Cristian",
	booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
	month = jul,
	year = "2015",
	address = "Beijing, China",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/P15-1159",
	doi = "10.3115/v1/P15-1159",
	pages = "1650--1659",
}

@inproceedings{potash-rumshisky-2017-towards,
	title = "Towards Debate Automation: a Recurrent Model for Predicting Debate Winners",
	author = "Potash, Peter  and
	Rumshisky, Anna",
	booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
	month = sep,
	year = "2017",
	address = "Copenhagen, Denmark",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/D17-1261",
	doi = "10.18653/v1/D17-1261",
	pages = "2465--2475",
	abstract = "In this paper we introduce a practical first step towards the creation of an automated debate agent: a state-of-the-art recurrent predictive model for predicting debate winners. By having an accurate predictive model, we are able to objectively rate the quality of a statement made at a specific turn in a debate. The model is based on a recurrent neural network architecture with attention, which allows the model to effectively account for the entire debate when making its prediction. Our model achieves state-of-the-art accuracy on a dataset of debate transcripts annotated with audience favorability of the debate teams. Finally, we discuss how future work can leverage our proposed model for the creation of an automated debate agent. We accomplish this by determining the model input that will maximize audience favorability toward a given side of a debate at an arbitrary turn.",
}

@inproceedings{artzi-etal-2012-predicting,
	title = "Predicting Responses to Microblog Posts",
	author = "Artzi, Yoav  and
	Pantel, Patrick  and
	Gamon, Michael",
	booktitle = "Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
	month = jun,
	year = "2012",
	address = "Montr{\'e}al, Canada",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/N12-1074",
	pages = "602--606",
}

@inproceedings{davidson-etal-2020-developing,
	title = "Developing a New Classifier for Automated Identification of Incivility in Social Media",
	author = "Davidson, Sam  and
	Sun, Qiusi  and
	Wojcieszak, Magdalena",
	booktitle = "Proceedings of the Fourth Workshop on Online Abuse and Harms",
	month = nov,
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/2020.alw-1.12",
	doi = "10.18653/v1/2020.alw-1.12",
	pages = "95--101",
	abstract = "Incivility is not only prevalent on online social media platforms, but also has concrete effects on individual users, online groups, and the platforms themselves. Given the prevalence and effects of online incivility, and the challenges involved in human-based incivility detection, it is urgent to develop validated and versatile automatic approaches to identifying uncivil posts and comments. This project advances both a neural, BERT-based classifier as well as a logistic regression classifier to identify uncivil comments. The classifier is trained on a dataset of Reddit posts, which are annotated for incivility, and further expanded using a combination of labeled data from Reddit and Twitter. Our best performing model achieves an F1 of 0.802 on our Reddit test set. The final model is not only applicable across social media platforms and their distinct data structures, but also computationally versatile, and - as such - ready to be used on vast volumes of online data. All trained models and annotated data are made available to the research community.",
}